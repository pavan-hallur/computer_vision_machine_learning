{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVML_Task5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('cvml_env': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "7aaef7f59f24aad306dcac3e74b8029415ae49a443303d43f6c447559d36a97a"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Colab works!\n",
        "# https://colab.research.google.com/drive/1cT7JMTar0T5OAhQs4GiIhi9EjJ_sRqRE?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORsREHWqHAha",
        "outputId": "f5df6ab2-4306-413c-f40e-0a66a1ada28d"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages (0.13.0)\nRequirement already satisfied: typeguard>=2.7 in /home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages (from tensorflow_addons) (2.12.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HSR9ELrF91D",
        "outputId": "b7576c08-2988-45f4-fc35-59d969cdb6e1"
      },
      "source": [
        "!git clone https://github.com/rogerhcheng/LiteFlowNet2-TF2.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LiteFlowNet2-TF2' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIvmiVyGFu7r",
        "outputId": "79a21e71-66cd-48a4-8be5-2504b553460d"
      },
      "source": [
        "cd LiteFlowNet2-TF2/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd04ovGiIOQc",
        "outputId": "10204f5b-88df-4194-af5b-7d3efc7c2068"
      },
      "source": [
        "# Run inference on the test images.\n",
        "# COPY IMAGES FOLDER !!! (frame1.png, frame2.png)\n",
        "\n",
        "\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "from model import LiteFlowNet2\n",
        "\n",
        "from draw_flow import flow_to_color\n",
        "\n",
        "tf.disable_eager_execution()\n",
        "\n",
        "\n",
        "def pad_image(image):\n",
        "    if len(image.shape) == 3:\n",
        "        h, w, c = image.shape\n",
        "    else:\n",
        "        h, w = image.shape\n",
        "        c = 1\n",
        "\n",
        "    nh = int(math.ceil(h / 32.) * 32)\n",
        "    nw = int(math.ceil(w / 32.) * 32)\n",
        "\n",
        "    pad_i = np.zeros([nh, nw, c])\n",
        "    pad_i[:h, :w] = image\n",
        "    return pad_i\n",
        "\n",
        "\n",
        "# Reset tf session.\n",
        "tf.reset_default_graph() \n",
        "\n",
        "# Create TF session.\n",
        "sess = tf.Session()\n",
        "model = LiteFlowNet2(isSintel=True)\n",
        "tens1 = tf.placeholder(tf.float32, shape=[None, None, None, 3])\n",
        "tens2 = tf.placeholder(tf.float32, shape=[None, None, None, 3])\n",
        "out = model(tens1, tens2)\n",
        "\n",
        "# Load model.\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, \"./models/LiteFlowNet2_Sintel_model\")\n",
        "\n",
        "\n",
        "# Load images.\n",
        "inp1 = cv2.imread(\"./../resources/frame1.png\")\n",
        "inp2 = cv2.imread(\"./../resources/frame2.png\")\n",
        "\n",
        "# Prepare input.\n",
        "w = inp1.shape[1]\n",
        "h = inp1.shape[0]\n",
        "inp1 = np.float32(np.expand_dims(pad_image(inp1), 0)) / 255.0\n",
        "inp2 = np.float32(np.expand_dims(pad_image(inp2), 0)) / 255.0\n",
        "\n",
        "# input in bgr format\n",
        "flow = sess.run(out, feed_dict={tens1: inp1, tens2: inp2})[0, :h, :w, :]\n",
        "\n",
        "\n",
        "# visualise flow with color model as image and save\n",
        "flow_image = flow_to_color(flow, convert_to_bgr=True)\n",
        "\n",
        "\n",
        "# Save output file.\n",
        "cv2.imwrite(\"out.png\", flow_image)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./models/LiteFlowNet2_Sintel_model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Computed input depth 2 doesn't match filter input depth 1\n\t [[node flownet/matching_2/flownet/matching_2/moduleUpflow/conv2d_transpose (defined at /home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py:56) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node flownet/matching_2/flownet/matching_2/moduleUpflow/conv2d_transpose:\n flownet/regularization_1/concat_2 (defined at /home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py:238)\n\nOriginal stack trace for 'flownet/matching_2/flownet/matching_2/moduleUpflow/conv2d_transpose':\n  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n    result = self._run_cell(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n    return runner(coro)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-e8c0bf99a920>\", line 39, in <module>\n    out = model(tens1, tens2)\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 292, in __call__\n    flow = self.matching(tensor_feat1[i], tensor_feat2[i], flow, lvls[i], name='matching_%i' % abs(i))\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 98, in matching\n    tensorFlow = module_upflow(tensorFlow)\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 73, in module_upflow\n    return self.group_upconv(x, 2, name + '/moduleUpflow')\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 56, in group_upconv\n    out = tf.nn.conv2d_transpose(in1, filterc, output_shape, strides=[1, 2, 2, 1])\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 2570, in conv2d_transpose_v2\n    return gen_nn_ops.conv2d_backprop_input(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1285, in conv2d_backprop_input\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3557, in _create_op_internal\n    ret = Operation(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m~/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
            "\u001b[0;32m~/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Computed input depth 2 doesn't match filter input depth 1\n\t [[{{node flownet/matching_2/flownet/matching_2/moduleUpflow/conv2d_transpose}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e8c0bf99a920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# input in bgr format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtens1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1394\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Computed input depth 2 doesn't match filter input depth 1\n\t [[node flownet/matching_2/flownet/matching_2/moduleUpflow/conv2d_transpose (defined at /home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py:56) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node flownet/matching_2/flownet/matching_2/moduleUpflow/conv2d_transpose:\n flownet/regularization_1/concat_2 (defined at /home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py:238)\n\nOriginal stack trace for 'flownet/matching_2/flownet/matching_2/moduleUpflow/conv2d_transpose':\n  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2898, in run_cell\n    result = self._run_cell(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n    return runner(coro)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3169, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-e8c0bf99a920>\", line 39, in <module>\n    out = model(tens1, tens2)\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 292, in __call__\n    flow = self.matching(tensor_feat1[i], tensor_feat2[i], flow, lvls[i], name='matching_%i' % abs(i))\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 98, in matching\n    tensorFlow = module_upflow(tensorFlow)\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 73, in module_upflow\n    return self.group_upconv(x, 2, name + '/moduleUpflow')\n  File \"/home/julian/workspace/cvml/sheet5/LiteFlowNet2-TF2/model.py\", line 56, in group_upconv\n    out = tf.nn.conv2d_transpose(in1, filterc, output_shape, strides=[1, 2, 2, 1])\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\", line 2570, in conv2d_transpose_v2\n    return gen_nn_ops.conv2d_backprop_input(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1285, in conv2d_backprop_input\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3557, in _create_op_internal\n    ret = Operation(\n  File \"/home/julian/workspace/cvml/cvml_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "NRGu8qMtHh8k",
        "outputId": "901afdc1-7df4-43f3-f1b2-1c50101f5581"
      },
      "source": [
        "# Show image in google colab.\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread(\"out.png\")\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3sXpJC1H4E8"
      },
      "source": []
    }
  ]
}